{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Define your features and target\n",
    "features = ['Voltage [V]', 'Current [A]', 'Temperature [degC]']\n",
    "target = 'SOC [-]'\n",
    "\n",
    "# Custom Dataset class\n",
    "class SOCDataset(Dataset):\n",
    "    def __init__(self, folder_path):\n",
    "        self.data = []\n",
    "        \n",
    "        # Load all CSV files in the specified folder\n",
    "        for file in os.listdir(folder_path):\n",
    "            if file.endswith('.csv'):\n",
    "                file_path = os.path.join(folder_path, file)\n",
    "                df = pd.read_csv(file_path)\n",
    "                \n",
    "                # Select only the relevant features and target\n",
    "                self.data.append(df[features + [target]])\n",
    "        \n",
    "        # Concatenate all dataframes into a single dataframe\n",
    "        self.data = pd.concat(self.data, ignore_index=True)\n",
    "\n",
    "        # Convert to tensors\n",
    "        self.X = torch.tensor(self.data[features].values, dtype=torch.float32)\n",
    "        self.y = torch.tensor(self.data[target].values, dtype=torch.float32).unsqueeze(1)  # Shape to (N, 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "\n",
    "# Positional Encoding\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)  # Shape: [max_len, 1, d_model]\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x should be of shape [seq_len, batch_size, d_model]\n",
    "        seq_len = x.size(0)\n",
    "        if seq_len > self.pe.size(0):\n",
    "            raise ValueError(\"Input sequence length exceeds the maximum length of positional encoding.\")\n",
    "        x = x + self.pe[:seq_len, :].detach()  # Add positional encoding\n",
    "        return x\n",
    "\n",
    "# Transformer Encoder Block\n",
    "class TransformerEncoderBlock(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super(TransformerEncoderBlock, self).__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, num_heads)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_ff, d_model)\n",
    "        )\n",
    "        self.layer_norm1 = nn.LayerNorm(d_model)\n",
    "        self.layer_norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        attn_output, _ = self.self_attn(x, x, x)\n",
    "        x = self.layer_norm1(x + self.dropout(attn_output))\n",
    "        ffn_output = self.ffn(x)\n",
    "        x = self.layer_norm2(x + self.dropout(ffn_output))\n",
    "        return x\n",
    "\n",
    "# Dual-Tower Transformer Architecture\n",
    "class BERTtery(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, num_layers, input_dim, dropout=0.1):\n",
    "        super(BERTtery, self).__init__()\n",
    "        self.positional_encoding = PositionalEncoding(d_model)\n",
    "        self.operational_embedding = nn.Linear(input_dim, d_model)\n",
    "        \n",
    "        # Temporal and Channel Encoders (Two-Tower Structure)\n",
    "        self.temporal_encoder = nn.ModuleList([\n",
    "            TransformerEncoderBlock(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)\n",
    "        ])\n",
    "        self.channel_encoder = nn.ModuleList([\n",
    "            TransformerEncoderBlock(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        # Gating Mechanism\n",
    "        self.gate = nn.Linear(d_model * 2, d_model)\n",
    "        \n",
    "        # Final Prediction Layer\n",
    "        self.fc = nn.Linear(d_model, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, seq_len, input_dim] - input features (voltage, current, temperature)\n",
    "        \n",
    "        # Apply Operational Embedding\n",
    "        x = self.operational_embedding(x)  # Shape: [batch_size, seq_len, d_model]\n",
    "        \n",
    "        # Transpose for transformer input: [seq_len, batch_size, d_model]\n",
    "        x = x.transpose(0, 1)\n",
    "\n",
    "        # Apply Positional Encoding\n",
    "        x = self.positional_encoding(x)  # Shape: [seq_len, batch_size, d_model]\n",
    "\n",
    "        # Temporal Encoder\n",
    "        x_temp = x  # Initialize x_temp\n",
    "        for layer in self.temporal_encoder:\n",
    "            x_temp = layer(x_temp)\n",
    "        \n",
    "        # Channel Encoder\n",
    "        x_chan = x  # Initialize x_chan\n",
    "        for layer in self.channel_encoder:\n",
    "            x_chan = layer(x_chan)\n",
    "\n",
    "        # Ensure both outputs are shaped correctly before concatenation\n",
    "        assert x_temp.shape == x_chan.shape, f\"Shapes do not match: {x_temp.shape} vs {x_chan.shape}\"\n",
    "\n",
    "        # Concatenate the two outputs and apply gating\n",
    "        x_concat = torch.cat((x_temp, x_chan), dim=-1)  # Shape: [seq_len, batch_size, 2*d_model]\n",
    "        \n",
    "        x_gate = torch.sigmoid(self.gate(x_concat))  # Apply gating\n",
    "        \n",
    "        # Final output layer (SOC prediction)\n",
    "        # Get the last time step: [batch_size, d_model]\n",
    "        output = self.fc(x_gate[-1])  # Take the last time step only\n",
    "\n",
    "        return output\n",
    "\n",
    "# Specify the folder where your CSV files are located\n",
    "folder_path = './dataset'  # Change this to your actual path\n",
    "\n",
    "# Create dataset and dataloader\n",
    "soc_dataset = SOCDataset(folder_path)\n",
    "dataloader = DataLoader(soc_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Define the model\n",
    "d_model = 64  # Dimension of model\n",
    "num_heads = 8  # Number of attention heads\n",
    "d_ff = 256  # Feed-forward network hidden size\n",
    "num_layers = 4  # Number of encoder layers\n",
    "input_dim = 3  # Input dimensions (Voltage, Current, Temperature)\n",
    "\n",
    "model = BERTtery(d_model, num_heads, d_ff, num_layers, input_dim)\n",
    "\n",
    "# Example Training Loop\n",
    "def train_model(model, dataloader, num_epochs=10):\n",
    "    model.train()  # Set the model to training mode\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.MSELoss()  # Mean Squared Error loss for regression tasks\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for inputs, labels in dataloader:\n",
    "            optimizer.zero_grad()  # Zero the gradients\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)  # Model expects [batch_size, seq_len, input_dim]\n",
    "            loss = criterion(outputs, labels)  # Compute the loss\n",
    "            loss.backward()  # Backpropagation\n",
    "            optimizer.step()  # Update the weights\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Train the model\n",
    "# train_model(model, dataloader, num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Awais\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Dataset class with a limit on the number of samples\n",
    "class BatteryDataset(Dataset):\n",
    "    def __init__(self, directory, features, target, limit=None):\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        self.data = []\n",
    "        self.cumulative_lengths = []  # Store cumulative lengths of each CSV\n",
    "        self.limit = limit\n",
    "        self.load_data(directory)\n",
    "    \n",
    "    def load_data(self, directory):\n",
    "        total_length = 0\n",
    "        for filename in os.listdir(directory):\n",
    "            if filename.endswith('.csv'):\n",
    "                filepath = os.path.join(directory, filename)\n",
    "                df = pd.read_csv(filepath)\n",
    "                self.data.append(df)\n",
    "                total_length += len(df)\n",
    "                self.cumulative_lengths.append(total_length)\n",
    "                if self.limit and total_length >= self.limit:\n",
    "                    break\n",
    "    \n",
    "    def __len__(self):\n",
    "        if self.limit:\n",
    "            return min(self.cumulative_lengths[-1], self.limit)\n",
    "        return self.cumulative_lengths[-1]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        for i, length in enumerate(self.cumulative_lengths):\n",
    "            if idx < length:\n",
    "                df = self.data[i]\n",
    "                if i > 0:\n",
    "                    row_idx = idx - self.cumulative_lengths[i-1]\n",
    "                else:\n",
    "                    row_idx = idx\n",
    "                break\n",
    "        else:\n",
    "            raise IndexError(f\"Index {idx} out of range\")\n",
    "\n",
    "        row = df.iloc[row_idx]\n",
    "        X = row[self.features].values.astype(np.float32)\n",
    "        y = row[self.target].astype(np.float32)\n",
    "        return torch.tensor(X), torch.tensor(y)\n",
    "\n",
    "# Positional encoding (sine-cosine encoding)\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return x\n",
    "\n",
    "# Transformer-based model\n",
    "class TransformerBatteryModel(nn.Module):\n",
    "    def __init__(self, input_dim, model_dim=64, num_layers=4, num_heads=8, dropout=0.1):\n",
    "        super(TransformerBatteryModel, self).__init__()\n",
    "        \n",
    "        self.input_embedding = nn.Linear(input_dim, model_dim)\n",
    "        self.positional_encoding = PositionalEncoding(d_model=model_dim)\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=model_dim, nhead=num_heads, dim_feedforward=256, dropout=dropout)\n",
    "        self.temporal_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.channel_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        self.gate = nn.Linear(2 * model_dim, model_dim)\n",
    "        self.fc = nn.Linear(model_dim, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.input_embedding(x)\n",
    "        x = self.positional_encoding(x)\n",
    "        \n",
    "        temporal_output = self.temporal_encoder(x)\n",
    "        channel_output = self.channel_encoder(x)\n",
    "        \n",
    "        combined_output = torch.cat((temporal_output, channel_output), dim=-1)\n",
    "        gated_output = torch.sigmoid(self.gate(combined_output))\n",
    "        \n",
    "        output = self.fc(gated_output.mean(dim=0))\n",
    "        return output\n",
    "\n",
    "# Hyperparameters\n",
    "input_dim = 3  # Number of features: Voltage, Current, Temperature\n",
    "model_dim = 64\n",
    "num_layers = 4\n",
    "num_heads = 8\n",
    "dropout = 0.1\n",
    "epochs = 130\n",
    "batch_size = 284\n",
    "learning_rate = 2.0\n",
    "gradient_clip_val = 1.0\n",
    "weight_decay = 0.0001\n",
    "validation_split = 0.2\n",
    "max_data_size = 4000  # Limit to 10k samples\n",
    "\n",
    "# Data preparation\n",
    "directory = './dataset'\n",
    "features = ['Voltage [V]', 'Current [A]', 'Temperature [degC]']\n",
    "target = 'SOC [-]'\n",
    "dataset = BatteryDataset(directory, features, target, limit=max_data_size)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_size = int((1 - validation_split) * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "# Model, optimizer, and loss function\n",
    "model = TransformerBatteryModel(input_dim=input_dim, model_dim=model_dim, num_layers=num_layers, num_heads=num_heads, dropout=dropout)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Training loop with validation loss printing\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets.unsqueeze(1))\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clip_val)\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Validation loss\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets.unsqueeze(1))\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch {epoch}, Training Loss: {running_loss/len(train_loader):.9f}, Validation Loss: {val_loss/len(val_loader):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
